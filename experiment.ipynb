{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Try to find class specific neurons in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 15:41:56.662888: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-18 15:41:56.703475: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-18 15:41:57.460521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 15:41:58.014879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-18 15:41:58.045018: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-18 15:41:58.045344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23410 files belonging to 2 classes.\n",
      "Using 18728 files for training.\n",
      "Using 4682 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 15:41:58.485767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-18 15:41:58.486223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-18 15:41:58.486298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-18 15:41:58.540782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-18 15:41:58.540947: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-18 15:41:58.541053: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-18 15:41:58.541201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2272 MB memory:  -> device: 0, name: NVIDIA RTX A2000 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "image_size = (180, 180)\n",
    "batch_size = 16 # My GPU could only handle this BS\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(f\"./models_from_server/model_cats_dogs/model/save_at_100.keras\")\n",
    "\n",
    "model.compile(\n",
    "    # optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    # loss=\"binary_crossentropy\", \n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 15:41:59.418095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/293 [..............................] - ETA: 4:14 - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 15:41:59.788014: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/293 [>.............................] - ETA: 12s - loss: 0.0000e+00 - accuracy: 0.9704"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31/293 [==>...........................] - ETA: 12s - loss: 0.0000e+00 - accuracy: 0.9637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/293 [=========>....................] - ETA: 8s - loss: 0.0000e+00 - accuracy: 0.9624"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/293 [============>.................] - ETA: 7s - loss: 0.0000e+00 - accuracy: 0.9610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/293 [====================>.........] - ETA: 3s - loss: 0.0000e+00 - accuracy: 0.9582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/293 [======================>.......] - ETA: 3s - loss: 0.0000e+00 - accuracy: 0.9589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 14s 46ms/step - loss: 0.0000e+00 - accuracy: 0.9579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.957923948764801]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 180, 180, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)       (None, 180, 180, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 90, 90, 128)          3584      ['rescaling[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 90, 90, 128)          512       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 90, 90, 128)          0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 90, 90, 128)          0         ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " separable_conv2d (Separabl  (None, 90, 90, 256)          34176     ['activation_1[0][0]']        \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 90, 90, 256)          1024      ['separable_conv2d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 90, 90, 256)          0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_1 (Separa  (None, 90, 90, 256)          68096     ['activation_2[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 90, 90, 256)          1024      ['separable_conv2d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 45, 45, 256)          0         ['batch_normalization_2[0][0]'\n",
      " D)                                                                 ]                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 45, 45, 256)          33024     ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 45, 45, 256)          0         ['max_pooling2d[0][0]',       \n",
      "                                                                     'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 45, 45, 256)          0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " separable_conv2d_2 (Separa  (None, 45, 45, 512)          133888    ['activation_3[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 45, 45, 512)          2048      ['separable_conv2d_2[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 45, 45, 512)          0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (Separa  (None, 45, 45, 512)          267264    ['activation_4[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 45, 45, 512)          2048      ['separable_conv2d_3[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 23, 23, 512)          0         ['batch_normalization_4[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 23, 23, 512)          131584    ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 23, 23, 512)          0         ['max_pooling2d_1[0][0]',     \n",
      "                                                                     'conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 23, 23, 512)          0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_4 (Separa  (None, 23, 23, 728)          378072    ['activation_5[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 23, 23, 728)          2912      ['separable_conv2d_4[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 23, 23, 728)          0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " separable_conv2d_5 (Separa  (None, 23, 23, 728)          537264    ['activation_6[0][0]']        \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 23, 23, 728)          2912      ['separable_conv2d_5[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 12, 12, 728)          0         ['batch_normalization_6[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 728)          373464    ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 12, 12, 728)          0         ['max_pooling2d_2[0][0]',     \n",
      "                                                                     'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " separable_conv2d_6 (Separa  (None, 12, 12, 1024)         753048    ['add_2[0][0]']               \n",
      " bleConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 12, 12, 1024)         4096      ['separable_conv2d_6[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 12, 12, 1024)         0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 1024)                 0         ['activation_7[0][0]']        \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1024)                 0         ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    1025      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2731065 (10.42 MB)\n",
      "Trainable params: 2722777 (10.39 MB)\n",
      "Non-trainable params: 8288 (32.38 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/293 [00:00<00:14, 19.55it/s]Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n",
      "  9%|▉         | 27/293 [00:01<00:13, 19.70it/s]Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      " 33%|███▎      | 98/293 [00:04<00:09, 20.00it/s]Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      " 44%|████▍     | 129/293 [00:06<00:08, 19.92it/s]Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      " 71%|███████   | 207/293 [00:10<00:04, 19.35it/s]Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      " 75%|███████▌  | 221/293 [00:11<00:03, 19.42it/s]Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n",
      "100%|██████████| 293/293 [00:14<00:00, 19.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary crossentropy loss: 0.5243650078773499\n",
      "Binary accuracy: 0.957923948764801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation loop\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "BC_loss = keras.metrics.BinaryCrossentropy(from_logits=True)\n",
    "binary_accuracy = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "for i, (x_batch_val, y_batch_val) in tqdm(enumerate(val_ds), total=len(val_ds)):\n",
    "\n",
    "# for x_batch_val, y_batch_val in val_ds:\n",
    "    val_logits = model(x_batch_val, training=False)\n",
    "    #\n",
    "\n",
    "    BC_loss.update_state(y_batch_val, val_logits)\n",
    "    binary_accuracy.update_state(y_batch_val, val_logits)\n",
    "    \n",
    "    # Update val metrics\n",
    "    # try:\n",
    "    #     # BC_loss.update_state(tf.reshape(val_logits, (16,1)), val_logits)\n",
    "    #     # binary_accuracy.update_state(tf.reshape(val_logits, (16,1)), val_logits)\n",
    "\n",
    "    #     BC_loss.update_state(y_batch_val, val_logits)\n",
    "    #     binary_accuracy.update_state(y_batch_val, val_logits)\n",
    "\n",
    "    # except:\n",
    "    #     # BC_loss.update_state(tf.reshape(val_logits, (len(val_logits),1)), val_logits)\n",
    "    #     # binary_accuracy.update_state(tf.reshape(val_logits, (len(val_logits),1)), val_logits)\n",
    "\n",
    "    #     BC_loss.update_state(y_batch_val, val_logits)\n",
    "    #     binary_accuracy.update_state(y_batch_val, val_logits)\n",
    " \n",
    "    # print(val_acc_metric.result())\n",
    "\n",
    "    # if i == 10:\n",
    "        \n",
    "    #     print(val_logits)\n",
    "    #     print(val_logits.shape)\n",
    "    #     print(\"======================\")\n",
    "    #     print(y_batch_val)\n",
    "    #     print(\"======================\")\n",
    "    #     print(tf.reshape(val_logits, (16,1)))\n",
    "    #     print(\"======================\")\n",
    "\n",
    "    #     print(tf.reshape(y_batch_val, [-1]))\n",
    "    #     # print(tf.reshape(val_logits, [-1]).shape)\n",
    "\n",
    "    #     print(len(val_logits))\n",
    "\n",
    "    #     break\n",
    "    \n",
    "# BC_loss = val_acc_metric.result()\n",
    "# val_acc_metric.reset_states()\n",
    "print(f\"Binary crossentropy loss: {BC_loss.result()}\")\n",
    "print(f\"Binary accuracy: {binary_accuracy.result()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
